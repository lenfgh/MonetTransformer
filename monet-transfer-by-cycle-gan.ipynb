{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'm Something of a Painter Myself\n",
    "\n",
    "*by Len Fu 2025/3/20*\n",
    "\n",
    "---\n",
    "\n",
    "A practice of GAN networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Dataset And Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the path to the Dataset\n",
    "ROOT_PATH = '/kaggle/input/gan-getting-started/'\n",
    "\n",
    "# Define the preprocessing procedure\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)), # Adjust the figsize\n",
    "        transforms.ToTensor(), # Transform to Torch Tensor\n",
    "        transforms.Normalize(\n",
    "            mean = [0.5, 0.5, 0.5],\n",
    "            std = [0.5, 0.5, 0.5]\n",
    "        ) # Normalise to standard form\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define the CustomDataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_folders, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_folders = target_folders\n",
    "        self.image_files = self._get_image_files()\n",
    "\n",
    "    def _get_image_files(self):\n",
    "        image_files = []\n",
    "        # Walk through the directories under the root directories\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            if folder_name in self.target_folders and os.path.isdir(folder_path):\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith('.jpg'):\n",
    "                        image_files.append(os.path.join(folder_path, file_name))\n",
    "        return image_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "class RepeatSampler(Sampler):\n",
    "    def __init__(self, data_source, target_length):\n",
    "        self.data_source = data_source\n",
    "        self.target_length = target_length\n",
    "        \n",
    "    def __iter__(self):\n",
    "\n",
    "        n_repeats = self.target_length // len(self.data_source) + 1\n",
    "\n",
    "        indices = []\n",
    "        for _ in range(n_repeats):\n",
    "            indices.extend(np.random.permutation(len(self.data_source)).tolist())\n",
    "\n",
    "        return iter(indices[:self.target_length])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.target_length\n",
    "\n",
    "# Load in the dataset\n",
    "monet_dataset = CustomDataset(\n",
    "    root_dir=ROOT_PATH,\n",
    "    target_folders=['monet_jpg'],\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "photo_dataset = CustomDataset(\n",
    "    root_dir=ROOT_PATH,\n",
    "    target_folders=['photo_jpg'],\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "# Create the batch loader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "\n",
    "monet_sampler = RepeatSampler(monet_dataset, len(photo_dataset))\n",
    "\n",
    "monet_dataloader = DataLoader(\n",
    "    dataset=monet_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    sampler=monet_sampler\n",
    ")\n",
    "\n",
    "photo_dataloader = DataLoader(\n",
    "    dataset=photo_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify whether the dataset is loaded successfully\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Ir-normalise\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some data\n",
    "monet_dataiter = iter(monet_dataloader)\n",
    "monet_images = next(monet_dataiter)\n",
    "\n",
    "photo_dataiter = iter(photo_dataloader)\n",
    "photo_images = next(photo_dataiter)\n",
    "\n",
    "# Show some Photo\n",
    "imshow(torchvision.utils.make_grid(monet_images[:4])) \n",
    "imshow(torchvision.utils.make_grid(photo_images[:4]))\n",
    "\n",
    "test_dataiter = iter(photo_dataloader)\n",
    "test_imgs = next(test_dataiter)\n",
    "\n",
    "print(\"DataLoader Output Form:\")\n",
    "print(\"Data Shape:\", test_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Structure of the Generator and the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CycleGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Define the architecture of the generator network.\n",
    "    Note: Both generators G_XtoY and G_YtoX have the same architecture in this assignment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conv_dim=256, input_channels=3, init_zero_weight=False):\n",
    "        super(CycleGenerator, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.res_blocks = nn.Sequential(*[\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=0),\n",
    "                nn.InstanceNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=0),\n",
    "                nn.InstanceNorm2d(128)\n",
    "            ) for _ in range(6)\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, input_channels, 7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.res_blocks(x) + x\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    The Discriminator is based on the structure of PatchGAN,\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conv_dim=256, input_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the generator Monet and Photo\n",
    "input_channels = 3\n",
    "generator_M = CycleGenerator()\n",
    "generator_P = CycleGenerator()\n",
    "\n",
    "# Initialize the discriminator Monet and Photo\n",
    "discriminator_M = Discriminator()\n",
    "discriminator_P = Discriminator()\n",
    "\n",
    "criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "criterion_cycle = nn.BCEWithLogitsLoss()\n",
    "criterion_identity = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "optimizer_MG  = torch.optim.Adam(generator_M.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_PG  = torch.optim.Adam(generator_P.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_MD  = torch.optim.Adam(discriminator_M.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_PD  = torch.optim.Adam(discriminator_P.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    generator_M = nn.DataParallel(generator_M)\n",
    "    generator_P = nn.DataParallel(generator_P)\n",
    "    discriminator_M = nn.DataParallel(discriminator_M)\n",
    "    discriminator_P = nn.DataParallel(discriminator_P)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generator_M.to(device), discriminator_M.to(device), generator_P.to(device), discriminator_P.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch_nums = 66\n",
    "\n",
    "for epoch in range(epoch_nums):   \n",
    "    for monet_imgs, photo_imgs in tqdm(zip(monet_dataloader, photo_dataloader), desc=f\"Epoch:{epoch+1}/{epoch_nums}\"):\n",
    "\n",
    "        if monet_imgs is None or photo_imgs is None:\n",
    "            continue\n",
    "            \n",
    "        monet_imgs = monet_imgs.to(device)\n",
    "        photo_imgs = photo_imgs.to(device)\n",
    "        \n",
    "\n",
    "        if monet_imgs.size(0) < photo_imgs.size(0) :\n",
    "            photo_imgs = photo_imgs[:monet_imgs.size(0)]\n",
    "        elif monet_imgs.size(0) > photo_imgs.size(0) :\n",
    "            monet_imgs = monet_imgs[:photo_imgs.size(0)]\n",
    "    \n",
    "        # Labels of real and fake figures\n",
    "        real_labels = torch.ones_like(discriminator_P(monet_imgs))*0.9\n",
    "        fake_labels = torch.zeros_like(discriminator_P(monet_imgs))*0.1\n",
    "    \n",
    "        # Train the photo discriminator\n",
    "        optimizer_PD.zero_grad()\n",
    "    \n",
    "        # Real imgs\n",
    "        real_imgs = photo_imgs  # Assuming photo_imgs are real images\n",
    "        outputs = discriminator_P(real_imgs)\n",
    "        d_loss_real = criterion_GAN(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "    \n",
    "        # Generate the fake imgs\n",
    "        fake_imgs = generator_P(monet_imgs).detach()  # Generate fake images from monet_imgs\n",
    "        outputs = discriminator_P(fake_imgs)\n",
    "        d_loss_fake = criterion_GAN(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "    \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimizer_PD.step()\n",
    "\n",
    "        # Train the monet discriminator\n",
    "        optimizer_MD.zero_grad()\n",
    "    \n",
    "        # Real imgs\n",
    "        real_imgs = monet_imgs  # Assuming photo_imgs are real images\n",
    "        outputs = discriminator_M(real_imgs)\n",
    "        d_loss_real = criterion_GAN(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "    \n",
    "        # Generate the fake imgs\n",
    "        fake_imgs = generator_M(photo_imgs).detach()  # Generate fake images from monet_imgs\n",
    "        outputs = discriminator_M(fake_imgs)\n",
    "        d_loss_fake = criterion_GAN(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "    \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimizer_MD.step()\n",
    "    \n",
    "        # Train the photo generator\n",
    "        optimizer_PG.zero_grad()\n",
    "    \n",
    "        fake_imgs = generator_P(monet_imgs)  # Generate fake images from monet_imgs\n",
    "        outputs = discriminator_P(fake_imgs)\n",
    "        g_loss_gan = criterion_GAN(outputs, real_labels)\n",
    "\n",
    "        reconstructed_imgs = generator_M(fake_imgs)\n",
    "        g_loss_cycle = criterion_cycle(reconstructed_imgs, monet_imgs)\n",
    "\n",
    "        identity_imgs = generator_P(photo_imgs)\n",
    "        g_loss_identity = criterion_identity(identity_imgs, photo_imgs)\n",
    "\n",
    "        g_loss = g_loss_gan + g_loss_cycle * 10 + g_loss_identity * 0.5\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_PG.step()\n",
    "\n",
    "        # Train the monet generator\n",
    "        optimizer_MG.zero_grad()\n",
    "    \n",
    "        fake_imgs = generator_M(photo_imgs)  # Generate fake images from monet_imgs\n",
    "        outputs = discriminator_M(fake_imgs)\n",
    "        g_loss_gan = criterion_GAN(outputs, real_labels)\n",
    "\n",
    "        reconstructed_imgs = generator_P(fake_imgs)\n",
    "        g_loss_cycle = criterion_cycle(reconstructed_imgs, photo_imgs)\n",
    "\n",
    "        identity_imgs = generator_M(monet_imgs)\n",
    "        g_loss_identity = criterion_identity(identity_imgs, monet_imgs)\n",
    "        \n",
    "        g_loss = g_loss_gan + g_loss_cycle * 10 + g_loss_identity * 0.5\n",
    "        g_loss.backward()\n",
    "        optimizer_MG.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            monet_to_photo = generator_P(monet_imgs[:5])\n",
    "            photo_to_monet = generator_M(photo_imgs[:5])\n",
    "        \n",
    "        plt.figure(figsize=(12, 8)) \n",
    "        \n",
    "        def denorm(tensor):\n",
    "            return tensor * 0.5 + 0.5  \n",
    "        \n",
    "        for j in range(5):\n",
    "            row = j\n",
    "            \n",
    "            plt.subplot(5, 4, row*4 + 1)\n",
    "            plt.imshow(denorm(monet_imgs[j].cpu().permute(1,2,0)))\n",
    "            plt.title(\"Monet Original\" if j==0 else \"\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(5, 4, row*4 + 2)\n",
    "            plt.imshow(denorm(monet_to_photo[j].cpu().permute(1,2,0)))\n",
    "            plt.title(\"Generated Photo\" if j==0 else \"\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(5, 4, row*4 + 3)\n",
    "            plt.imshow(denorm(photo_imgs[j].cpu().permute(1,2,0)))\n",
    "            plt.title(\"Photo Original\" if j==0 else \"\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(5, 4, row*4 + 4)\n",
    "            plt.imshow(denorm(photo_to_monet[j].cpu().permute(1,2,0)))\n",
    "            plt.title(\"Generated Monet\" if j==0 else \"\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "# Save the trained encoder and trained decoder\n",
    "torch.save(generator_M.state_dict(), '../models/generator_M.pth')\n",
    "torch.save(generator_P.state_dict(), '../models/generator_P.pth')\n",
    "torch.save(discriminator_M.state_dict(), '../models/discriminator_M.pth')\n",
    "torch.save(discriminator_P.state_dict(), '../models/discriminator_P.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('../images', exist_ok=True)\n",
    "\n",
    "generator_M.eval()  \n",
    "\n",
    "i = 0  \n",
    "with torch.no_grad():\n",
    "    for batch_idx, imgs in enumerate(tqdm(photo_dataloader, desc='Generating Images')):\n",
    "        imgs = imgs.to(device)\n",
    "        generated_imgs = generator_M(imgs)\n",
    "        \n",
    "        for j in range(generated_imgs.size(0)):\n",
    "            generated_img = generated_imgs[j].cpu()\n",
    "            generated_img = generated_img * 0.5 + 0.5  # [-1,1] â†’ [0,1]\n",
    "            generated_img = generated_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "            generated_img = np.clip(generated_img, 0.0, 1.0)\n",
    "\n",
    "            plt.imsave(f\"../images/{i}.jpg\", generated_img)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Zip the created figures\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['encoder.0.weight', 'encoder.0.bias', 'res_blocks.0.1.weight', 'res_blocks.0.1.bias', 'res_blocks.0.5.weight', 'res_blocks.0.5.bias', 'res_blocks.1.1.weight', 'res_blocks.1.1.bias', 'res_blocks.1.5.weight', 'res_blocks.1.5.bias', 'res_blocks.2.1.weight', 'res_blocks.2.1.bias', 'res_blocks.2.5.weight', 'res_blocks.2.5.bias', 'res_blocks.3.1.weight', 'res_blocks.3.1.bias', 'res_blocks.3.5.weight', 'res_blocks.3.5.bias', 'res_blocks.4.1.weight', 'res_blocks.4.1.bias', 'res_blocks.4.5.weight', 'res_blocks.4.5.bias', 'res_blocks.5.1.weight', 'res_blocks.5.1.bias', 'res_blocks.5.5.weight', 'res_blocks.5.5.bias', 'decoder.0.weight', 'decoder.0.bias', 'decoder.3.weight', 'decoder.3.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_file = torch.load('./models/generator_M.pth', map_location='cpu')\n",
    "\n",
    "print(model_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "isSourceIdPinned": false,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
